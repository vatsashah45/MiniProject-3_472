{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a5f5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d469b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enormously</td>\n",
       "      <td>tremendously</td>\n",
       "      <td>appropriately</td>\n",
       "      <td>uniquely</td>\n",
       "      <td>tremendously</td>\n",
       "      <td>decidedly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>provisions</td>\n",
       "      <td>stipulations</td>\n",
       "      <td>stipulations</td>\n",
       "      <td>interrelations</td>\n",
       "      <td>jurisdictions</td>\n",
       "      <td>interpretations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haphazardly</td>\n",
       "      <td>randomly</td>\n",
       "      <td>dangerously</td>\n",
       "      <td>densely</td>\n",
       "      <td>randomly</td>\n",
       "      <td>linearly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prominent</td>\n",
       "      <td>conspicuous</td>\n",
       "      <td>battered</td>\n",
       "      <td>ancient</td>\n",
       "      <td>mysterious</td>\n",
       "      <td>conspicuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zenith</td>\n",
       "      <td>pinnacle</td>\n",
       "      <td>completion</td>\n",
       "      <td>pinnacle</td>\n",
       "      <td>outset</td>\n",
       "      <td>decline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fashion</td>\n",
       "      <td>manner</td>\n",
       "      <td>ration</td>\n",
       "      <td>fathom</td>\n",
       "      <td>craze</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>marketed</td>\n",
       "      <td>sold</td>\n",
       "      <td>frozen</td>\n",
       "      <td>sold</td>\n",
       "      <td>sweetened</td>\n",
       "      <td>diluted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>bigger</td>\n",
       "      <td>larger</td>\n",
       "      <td>steadier</td>\n",
       "      <td>closer</td>\n",
       "      <td>larger</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>roots</td>\n",
       "      <td>origins</td>\n",
       "      <td>origins</td>\n",
       "      <td>rituals</td>\n",
       "      <td>cure</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>normally</td>\n",
       "      <td>ordinarily</td>\n",
       "      <td>haltingly</td>\n",
       "      <td>ordinarily</td>\n",
       "      <td>permanently</td>\n",
       "      <td>periodically</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question        answer              0               1              2  \\\n",
       "0    enormously  tremendously  appropriately        uniquely   tremendously   \n",
       "1    provisions  stipulations   stipulations  interrelations  jurisdictions   \n",
       "2   haphazardly      randomly    dangerously         densely       randomly   \n",
       "3     prominent   conspicuous       battered         ancient     mysterious   \n",
       "4        zenith      pinnacle     completion        pinnacle         outset   \n",
       "..          ...           ...            ...             ...            ...   \n",
       "75      fashion        manner         ration          fathom          craze   \n",
       "76     marketed          sold         frozen            sold      sweetened   \n",
       "77       bigger        larger       steadier          closer         larger   \n",
       "78        roots       origins        origins         rituals           cure   \n",
       "79     normally    ordinarily      haltingly      ordinarily    permanently   \n",
       "\n",
       "                  3  \n",
       "0         decidedly  \n",
       "1   interpretations  \n",
       "2          linearly  \n",
       "3       conspicuous  \n",
       "4           decline  \n",
       "..              ...  \n",
       "75           manner  \n",
       "76          diluted  \n",
       "77           better  \n",
       "78         function  \n",
       "79     periodically  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('synonyms.csv', sep=\",\",header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9ddf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'word2vec-google-news-300'\n",
    "word2vec = gensim.downloader.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d81e8444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enormously,tremendously,tremendously,correct\n",
      "provisions,stipulations,stipulations,correct\n",
      "haphazardly,randomly,randomly,correct\n",
      "prominent,conspicuous,conspicuous,correct\n",
      "zenith,pinnacle,pinnacle,correct\n",
      "flawed,imperfect,imperfect,correct\n",
      "urgently,desperately,desperately,correct\n",
      "consumed,eaten,eaten,correct\n",
      "advent,coming,coming,correct\n",
      "concisely,succinctly,succinctly,correct\n",
      "salutes,greetings,ceremonies,wrong\n",
      "solitary,alone,restless,wrong\n",
      "hasten,accelerate,accelerate,correct\n",
      "perseverance,endurance,generosity,wrong\n",
      "fanciful,imaginative,imaginative,correct\n",
      "showed,demonstrated,demonstrated,correct\n",
      "constantly,continually,continually,correct\n",
      "issues,subjects,subjects,correct\n",
      "furnish,supply,impress,wrong\n",
      "costly,expensive,expensive,correct\n",
      "recognized,acknowledged,acknowledged,correct\n",
      "spot,location,location,correct\n",
      "make,earn,earn,correct\n",
      "often,frequently,frequently,correct\n",
      "easygoing,relaxed,relaxed,correct\n",
      "debate,argument,argument,correct\n",
      "narrow,thin,thin,correct\n",
      "arranged,planned,planned,correct\n",
      "infinite,limitless,limitless,correct\n",
      "showy,striking,prickly,wrong\n",
      "levied,imposed,imposed,correct\n",
      "deftly,skillfully,skillfully,correct\n",
      "distribute,circulate,commercialize,wrong\n",
      "discrepancies,differences,differences,correct\n",
      "prolific,productive,productive,correct\n",
      "unmatched,unequaled,unequaled,correct\n",
      "peculiarly,uniquely,uniquely,correct\n",
      "hue,color,color,correct\n",
      "hind,rear,rear,correct\n",
      "highlight,accentuate,accentuate,correct\n",
      "hastily,hurriedly,hurriedly,correct\n",
      "temperate,mild,mild,correct\n",
      "grin,smile,smile,correct\n",
      "verbally,orally,orally,correct\n",
      "physician,doctor,doctor,correct\n",
      "essentially,basically,basically,correct\n",
      "keen,sharp,useful,wrong\n",
      "situated,positioned,positioned,correct\n",
      "principal,major,major,correct\n",
      "slowly,gradually,gradually,correct\n",
      "built,constructed,constructed,correct\n",
      "tasks,jobs,jobs,correct\n",
      "unlikely,improbable,improbable,correct\n",
      "halfheartedly,apathetically,apathetically,correct\n",
      "annals,chronicles,chronicles,correct\n",
      "wildly,furiously,furiously,correct\n",
      "hailed,acclaimed,remembered,wrong\n",
      "command,mastery,mastery,correct\n",
      "concocted,devised,devised,correct\n",
      "prospective,potential,potential,correct\n",
      "generally,broadly,broadly,correct\n",
      "sustained,prolonged,prolonged,correct\n",
      "perilous,dangerous,dangerous,correct\n",
      "tranquillity,peacefulness,happiness,guess\n",
      "dissipate,disperse,disperse,correct\n",
      "primarily,chiefly,chiefly,correct\n",
      "colloquial,conversational,conversational,correct\n",
      "resolved,settled,settled,correct\n",
      "feasible,possible,possible,correct\n",
      "expeditiously,rapidly,rapidly,correct\n",
      "percentage,proportion,proportion,correct\n",
      "terminated,ended,postponed,wrong\n",
      "uniform,alike,alike,correct\n",
      "figure,solve,solve,correct\n",
      "sufficient,enough,enough,correct\n",
      "fashion,manner,manner,correct\n",
      "marketed,sold,sold,correct\n",
      "bigger,larger,larger,correct\n",
      "roots,origins,origins,correct\n",
      "normally,ordinarily,ordinarily,correct\n"
     ]
    }
   ],
   "source": [
    "L_pred = []\n",
    "for row in data.iterrows():\n",
    "    if row[1][\"question\"] in word2vec.key_to_index and row[1][\"answer\"] in word2vec.key_to_index:\n",
    "        prediction = []\n",
    "        if row[1][\"0\"] in word2vec.key_to_index:\n",
    "            prediction.append([row[1]['0'], word2vec.similarity(row[1]['0'], row[1]['question'])]) \n",
    "            \n",
    "        if row[1][\"1\"] in word2vec.key_to_index:\n",
    "            prediction.append([row[1]['1'], word2vec.similarity(row[1]['1'], row[1]['question'])])\n",
    "            \n",
    "        if row[1][\"2\"] in word2vec.key_to_index:\n",
    "            prediction.append([row[1]['2'], word2vec.similarity(row[1]['2'], row[1]['question'])])\n",
    "            \n",
    "        if row[1][\"3\"] in word2vec.key_to_index:\n",
    "            prediction.append([row[1]['3'], word2vec.similarity(row[1]['3'], row[1]['question'])])\n",
    "        \n",
    "        if len(prediction)!=0:\n",
    "            guess = max(prediction, key=lambda x: x[1])\n",
    "            if guess[0] == row[1][\"answer\"]:\n",
    "                label='correct'\n",
    "            else:\n",
    "                label='wrong'\n",
    "        else:\n",
    "            label = 'guess'\n",
    "            guess = [row[1][str(np.random.randint(0,4))]]\n",
    "            \n",
    "    else:\n",
    "        label = 'guess'\n",
    "        guess = [row[1][str(np.random.randint(0,4))]]\n",
    "    s = F\"{row[1]['question']},{row[1]['answer']},{guess[0]},{label}\"\n",
    "    L_pred.append(s)\n",
    "\n",
    "with open(f\"{model}-details.csv\",'w') as f:\n",
    "    for pred in L_pred:\n",
    "        f.write(pred+'\\n')\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc162b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec-google-news-300,3000000,70,79,0.8860759493670886\n"
     ]
    }
   ],
   "source": [
    "L_pred = []\n",
    "with open(f\"{model}-details.csv\",'r') as f:\n",
    "    for line in f.readlines():\n",
    "        L_pred.append(line.split(','))\n",
    "        L_pred[-1][-1] = L_pred[-1][-1].rstrip(\"\\n\")\n",
    "C = list(map(lambda x:x[-1],L_pred)).count(\"correct\")\n",
    "V = list(map(lambda x:x[-1],L_pred)).count(\"wrong\") + C\n",
    "\n",
    "with open(\"analysis.csv\", \"w\") as f:\n",
    "    f.write(f\"{model},{len(word2vec.key_to_index)},{C},{V},{C/V}\\n\")\n",
    "    print(f\"{model},{len(word2vec.key_to_index)},{C},{V},{C/V}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c5086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9375efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
